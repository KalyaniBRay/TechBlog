{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk : Natural Language Toolkit\n",
    "### corpus word coming from corpora. corpus meaning 'collection of words'. corpora is universal all stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KALYANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\KALYANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\KALYANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KALYANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"stopwords\", \"state_union\", \"twitter_samples\", \"punkt\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'إلا',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللاتي',\n",
       " 'اللائي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أما',\n",
       " 'إما',\n",
       " 'أن',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'أنى',\n",
       " 'أنى',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'أو',\n",
       " 'أولاء',\n",
       " 'أولئك',\n",
       " 'أوه',\n",
       " 'آي',\n",
       " 'أي',\n",
       " 'أيها',\n",
       " 'إي',\n",
       " 'أين',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'إيه',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بين',\n",
       " 'بيد',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'لئن',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'منذ',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هؤلاء',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا',\n",
       " 'أبٌ',\n",
       " 'أخٌ',\n",
       " 'حمٌ',\n",
       " 'فو',\n",
       " 'أنتِ',\n",
       " 'يناير',\n",
       " 'فبراير',\n",
       " 'مارس',\n",
       " 'أبريل',\n",
       " 'مايو',\n",
       " 'يونيو',\n",
       " 'يوليو',\n",
       " 'أغسطس',\n",
       " 'سبتمبر',\n",
       " 'أكتوبر',\n",
       " 'نوفمبر',\n",
       " 'ديسمبر',\n",
       " 'جانفي',\n",
       " 'فيفري',\n",
       " 'مارس',\n",
       " 'أفريل',\n",
       " 'ماي',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'أوت',\n",
       " 'كانون',\n",
       " 'شباط',\n",
       " 'آذار',\n",
       " 'نيسان',\n",
       " 'أيار',\n",
       " 'حزيران',\n",
       " 'تموز',\n",
       " 'آب',\n",
       " 'أيلول',\n",
       " 'تشرين',\n",
       " 'دولار',\n",
       " 'دينار',\n",
       " 'ريال',\n",
       " 'درهم',\n",
       " 'ليرة',\n",
       " 'جنيه',\n",
       " 'قرش',\n",
       " 'مليم',\n",
       " 'فلس',\n",
       " 'هللة',\n",
       " 'سنتيم',\n",
       " 'يورو',\n",
       " 'ين',\n",
       " 'يوان',\n",
       " 'شيكل',\n",
       " 'واحد',\n",
       " 'اثنان',\n",
       " 'ثلاثة',\n",
       " 'أربعة',\n",
       " 'خمسة',\n",
       " 'ستة',\n",
       " 'سبعة',\n",
       " 'ثمانية',\n",
       " 'تسعة',\n",
       " 'عشرة',\n",
       " 'أحد',\n",
       " 'اثنا',\n",
       " 'اثني',\n",
       " 'إحدى',\n",
       " 'ثلاث',\n",
       " 'أربع',\n",
       " 'خمس',\n",
       " 'ست',\n",
       " 'سبع',\n",
       " 'ثماني',\n",
       " 'تسع',\n",
       " 'عشر',\n",
       " 'ثمان',\n",
       " 'سبت',\n",
       " 'أحد',\n",
       " 'اثنين',\n",
       " 'ثلاثاء',\n",
       " 'أربعاء',\n",
       " 'خميس',\n",
       " 'جمعة',\n",
       " 'أول',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثالث',\n",
       " 'رابع',\n",
       " 'خامس',\n",
       " 'سادس',\n",
       " 'سابع',\n",
       " 'ثامن',\n",
       " 'تاسع',\n",
       " 'عاشر',\n",
       " 'حادي',\n",
       " 'أ',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ء',\n",
       " 'ى',\n",
       " 'آ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'أ',\n",
       " 'ة',\n",
       " 'ألف',\n",
       " 'باء',\n",
       " 'تاء',\n",
       " 'ثاء',\n",
       " 'جيم',\n",
       " 'حاء',\n",
       " 'خاء',\n",
       " 'دال',\n",
       " 'ذال',\n",
       " 'راء',\n",
       " 'زاي',\n",
       " 'سين',\n",
       " 'شين',\n",
       " 'صاد',\n",
       " 'ضاد',\n",
       " 'طاء',\n",
       " 'ظاء',\n",
       " 'عين',\n",
       " 'غين',\n",
       " 'فاء',\n",
       " 'قاف',\n",
       " 'كاف',\n",
       " 'لام',\n",
       " 'ميم',\n",
       " 'نون',\n",
       " 'هاء',\n",
       " 'واو',\n",
       " 'ياء',\n",
       " 'همزة',\n",
       " 'ي',\n",
       " 'نا',\n",
       " 'ك',\n",
       " 'كن',\n",
       " 'ه',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهما',\n",
       " 'إياهم',\n",
       " 'إياهن',\n",
       " 'إياك',\n",
       " 'إياكما',\n",
       " 'إياكم',\n",
       " 'إياك',\n",
       " 'إياكن',\n",
       " 'إياي',\n",
       " 'إيانا',\n",
       " 'أولالك',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'تَيْنِ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ذانِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ذَيْنِ',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَذَيْنِ',\n",
       " 'الألى',\n",
       " 'الألاء',\n",
       " 'أل',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'ذيت',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'بضع',\n",
       " 'فلان',\n",
       " 'وا',\n",
       " 'آمينَ',\n",
       " 'آهِ',\n",
       " 'آهٍ',\n",
       " 'آهاً',\n",
       " 'أُفٍّ',\n",
       " 'أُفٍّ',\n",
       " 'أفٍّ',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أوّهْ',\n",
       " 'إلَيْكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إليكَ',\n",
       " 'إليكنّ',\n",
       " 'إيهٍ',\n",
       " 'بخٍ',\n",
       " 'بسّ',\n",
       " 'بَسْ',\n",
       " 'بطآن',\n",
       " 'بَلْهَ',\n",
       " 'حاي',\n",
       " 'حَذارِ',\n",
       " 'حيَّ',\n",
       " 'حيَّ',\n",
       " 'دونك',\n",
       " 'رويدك',\n",
       " 'سرعان',\n",
       " 'شتانَ',\n",
       " 'شَتَّانَ',\n",
       " 'صهْ',\n",
       " 'صهٍ',\n",
       " 'طاق',\n",
       " 'طَق',\n",
       " 'عَدَسْ',\n",
       " 'كِخ',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'نَخْ',\n",
       " 'هاكَ',\n",
       " 'هَجْ',\n",
       " 'هلم',\n",
       " 'هيّا',\n",
       " 'هَيْهات',\n",
       " 'وا',\n",
       " 'واهاً',\n",
       " 'وراءَك',\n",
       " 'وُشْكَانَ',\n",
       " 'وَيْ',\n",
       " 'يفعلان',\n",
       " 'تفعلان',\n",
       " 'يفعلون',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'اتخذ',\n",
       " 'ألفى',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تعلَّم',\n",
       " 'جعل',\n",
       " 'حجا',\n",
       " 'حبيب',\n",
       " 'خال',\n",
       " 'حسب',\n",
       " 'خال',\n",
       " 'درى',\n",
       " 'رأى',\n",
       " 'زعم',\n",
       " 'صبر',\n",
       " 'ظنَّ',\n",
       " 'عدَّ',\n",
       " 'علم',\n",
       " 'غادر',\n",
       " 'ذهب',\n",
       " 'وجد',\n",
       " 'ورد',\n",
       " 'وهب',\n",
       " 'أسكن',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'رزق',\n",
       " 'زود',\n",
       " 'سقى',\n",
       " 'كسا',\n",
       " 'أخبر',\n",
       " 'أرى',\n",
       " 'أعلم',\n",
       " 'أنبأ',\n",
       " 'حدَث',\n",
       " 'خبَّر',\n",
       " 'نبَّا',\n",
       " 'أفعل به',\n",
       " 'ما أفعله',\n",
       " 'بئس',\n",
       " 'ساء',\n",
       " 'طالما',\n",
       " 'قلما',\n",
       " 'لات',\n",
       " 'لكنَّ',\n",
       " 'ءَ',\n",
       " 'أجل',\n",
       " 'إذاً',\n",
       " 'أمّا',\n",
       " 'إمّا',\n",
       " 'إنَّ',\n",
       " 'أنًّ',\n",
       " 'أى',\n",
       " 'إى',\n",
       " 'أيا',\n",
       " 'ب',\n",
       " 'ثمَّ',\n",
       " 'جلل',\n",
       " 'جير',\n",
       " 'رُبَّ',\n",
       " 'س',\n",
       " 'علًّ',\n",
       " 'ف',\n",
       " 'كأنّ',\n",
       " 'كلَّا',\n",
       " 'كى',\n",
       " 'ل',\n",
       " 'لات',\n",
       " 'لعلَّ',\n",
       " 'لكنَّ',\n",
       " 'لكنَّ',\n",
       " 'م',\n",
       " 'نَّ',\n",
       " 'هلّا',\n",
       " 'وا',\n",
       " 'أل',\n",
       " 'إلّا',\n",
       " 'ت',\n",
       " 'ك',\n",
       " 'لمّا',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ا',\n",
       " 'ي',\n",
       " 'تجاه',\n",
       " 'تلقاء',\n",
       " 'جميع',\n",
       " 'حسب',\n",
       " 'سبحان',\n",
       " 'شبه',\n",
       " 'لعمر',\n",
       " 'مثل',\n",
       " 'معاذ',\n",
       " 'أبو',\n",
       " 'أخو',\n",
       " 'حمو',\n",
       " 'فو',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ثلاثمئة',\n",
       " 'أربعمئة',\n",
       " 'خمسمئة',\n",
       " 'ستمئة',\n",
       " 'سبعمئة',\n",
       " 'ثمنمئة',\n",
       " 'تسعمئة',\n",
       " 'مائة',\n",
       " 'ثلاثمائة',\n",
       " 'أربعمائة',\n",
       " 'خمسمائة',\n",
       " 'ستمائة',\n",
       " 'سبعمائة',\n",
       " 'ثمانمئة',\n",
       " 'تسعمائة',\n",
       " 'عشرون',\n",
       " 'ثلاثون',\n",
       " 'اربعون',\n",
       " 'خمسون',\n",
       " 'ستون',\n",
       " 'سبعون',\n",
       " 'ثمانون',\n",
       " 'تسعون',\n",
       " 'عشرين',\n",
       " 'ثلاثين',\n",
       " 'اربعين',\n",
       " 'خمسين',\n",
       " 'ستين',\n",
       " 'سبعين',\n",
       " 'ثمانين',\n",
       " 'تسعين',\n",
       " 'بضع',\n",
       " 'نيف',\n",
       " 'أجمع',\n",
       " 'جميع',\n",
       " 'عامة',\n",
       " 'عين',\n",
       " 'نفس',\n",
       " 'لا سيما',\n",
       " 'أصلا',\n",
       " 'أهلا',\n",
       " 'أيضا',\n",
       " 'بؤسا',\n",
       " 'بعدا',\n",
       " 'بغتة',\n",
       " 'تعسا',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'خلافا',\n",
       " 'خاصة',\n",
       " 'دواليك',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سمعا',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'طرا',\n",
       " 'عجبا',\n",
       " 'عيانا',\n",
       " 'غالبا',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'قاطبة',\n",
       " 'كثيرا',\n",
       " 'لبيك',\n",
       " 'معاذ',\n",
       " 'أبدا',\n",
       " 'إزاء',\n",
       " 'أصلا',\n",
       " 'الآن',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'آنفا',\n",
       " 'آناء',\n",
       " 'أنّى',\n",
       " 'أول',\n",
       " 'أيّان',\n",
       " 'تارة',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'حقا',\n",
       " 'صباح',\n",
       " 'مساء',\n",
       " 'ضحوة',\n",
       " 'عوض',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'قطّ',\n",
       " 'كلّما',\n",
       " 'لدن',\n",
       " 'لمّا',\n",
       " 'مرّة',\n",
       " 'قبل',\n",
       " 'خلف',\n",
       " 'أمام',\n",
       " 'فوق',\n",
       " 'تحت',\n",
       " 'يمين',\n",
       " 'شمال',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'أصبح',\n",
       " 'أضحى',\n",
       " 'آض',\n",
       " 'أمسى',\n",
       " 'انقلب',\n",
       " 'بات',\n",
       " 'تبدّل',\n",
       " 'تحوّل',\n",
       " 'حار',\n",
       " 'رجع',\n",
       " 'راح',\n",
       " 'صار',\n",
       " 'ظلّ',\n",
       " 'عاد',\n",
       " 'غدا',\n",
       " 'كان',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مادام',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ابتدأ',\n",
       " 'أخذ',\n",
       " 'اخلولق',\n",
       " 'أقبل',\n",
       " 'انبرى',\n",
       " 'أنشأ',\n",
       " 'أوشك',\n",
       " 'جعل',\n",
       " 'حرى',\n",
       " 'شرع',\n",
       " 'طفق',\n",
       " 'علق',\n",
       " 'قام',\n",
       " 'كرب',\n",
       " 'كاد',\n",
       " 'هبّa',\n",
       " 'ad',\n",
       " 'altı',\n",
       " 'altmış',\n",
       " 'amma',\n",
       " 'arasında',\n",
       " 'artıq',\n",
       " 'ay',\n",
       " 'az',\n",
       " 'bax',\n",
       " 'belə',\n",
       " 'bəli',\n",
       " 'bəlkə',\n",
       " 'beş',\n",
       " 'bəy',\n",
       " 'bəzən',\n",
       " 'bəzi',\n",
       " 'bilər',\n",
       " 'bir',\n",
       " 'biraz',\n",
       " 'biri',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bizim',\n",
       " 'bizlər',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bundan',\n",
       " 'bunların',\n",
       " 'bunu',\n",
       " 'bunun',\n",
       " 'buradan',\n",
       " 'bütün',\n",
       " 'ci',\n",
       " 'cı',\n",
       " 'çox',\n",
       " 'cu',\n",
       " 'cü',\n",
       " 'çünki',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'də',\n",
       " 'dedi',\n",
       " 'dək',\n",
       " 'dən',\n",
       " 'dəqiqə',\n",
       " 'deyil',\n",
       " 'dir',\n",
       " 'doqquz',\n",
       " 'doqsan',\n",
       " 'dörd',\n",
       " 'düz',\n",
       " 'ə',\n",
       " 'edən',\n",
       " 'edir',\n",
       " 'əgər',\n",
       " 'əlbəttə',\n",
       " 'elə',\n",
       " 'əlli',\n",
       " 'ən',\n",
       " 'əslində',\n",
       " 'et',\n",
       " 'etdi',\n",
       " 'etmə',\n",
       " 'etmək',\n",
       " 'faiz',\n",
       " 'gilə',\n",
       " 'görə',\n",
       " 'ha',\n",
       " 'haqqında',\n",
       " 'harada',\n",
       " 'hə',\n",
       " 'heç',\n",
       " 'həm',\n",
       " 'həmin',\n",
       " 'həmişə',\n",
       " 'hər',\n",
       " 'ı',\n",
       " 'idi',\n",
       " 'iki',\n",
       " 'il',\n",
       " 'ildə',\n",
       " 'ilə',\n",
       " 'ilk',\n",
       " 'in',\n",
       " 'indi',\n",
       " 'isə',\n",
       " 'istifadə',\n",
       " 'iyirmi',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'kimə',\n",
       " 'kimi',\n",
       " 'lakin',\n",
       " 'lap',\n",
       " 'məhz',\n",
       " 'mən',\n",
       " 'mənə',\n",
       " 'mirşey',\n",
       " 'nə',\n",
       " 'nəhayət',\n",
       " 'niyə',\n",
       " 'o',\n",
       " 'obirisi',\n",
       " 'of',\n",
       " 'olan',\n",
       " 'olar',\n",
       " 'olaraq',\n",
       " 'oldu',\n",
       " 'olduğu',\n",
       " 'olmadı',\n",
       " 'olmaz',\n",
       " 'olmuşdur',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'on',\n",
       " 'ona',\n",
       " 'ondan',\n",
       " 'onlar',\n",
       " 'onlardan',\n",
       " 'onların ',\n",
       " 'onsuzda',\n",
       " 'onu',\n",
       " 'onun',\n",
       " 'oradan',\n",
       " 'otuz',\n",
       " 'öz',\n",
       " 'özü',\n",
       " 'qarşı',\n",
       " 'qədər',\n",
       " 'qırx',\n",
       " 'saat',\n",
       " 'sadəcə',\n",
       " 'saniyə',\n",
       " 'səhv',\n",
       " 'səkkiz',\n",
       " 'səksən',\n",
       " 'sən',\n",
       " 'sənə',\n",
       " 'sənin',\n",
       " 'siz',\n",
       " 'sizin',\n",
       " 'sizlər',\n",
       " 'sonra',\n",
       " 'təəssüf',\n",
       " 'ü',\n",
       " 'üç',\n",
       " 'üçün',\n",
       " 'var',\n",
       " 'və',\n",
       " 'xan',\n",
       " 'xanım',\n",
       " 'xeyr',\n",
       " 'ya',\n",
       " 'yalnız',\n",
       " 'yaxşı',\n",
       " 'yeddi',\n",
       " 'yenə',\n",
       " 'yəni',\n",
       " 'yetmiş',\n",
       " 'yox',\n",
       " 'yoxdur',\n",
       " 'yoxsa',\n",
       " 'yüz',\n",
       " 'zamanahala',\n",
       " 'aitzitik',\n",
       " 'al',\n",
       " 'ala ',\n",
       " 'alabadere',\n",
       " 'alabaina',\n",
       " 'alabaina',\n",
       " 'aldiz ',\n",
       " 'alta',\n",
       " 'amaitu',\n",
       " 'amaitzeko',\n",
       " 'anitz',\n",
       " 'antzina',\n",
       " 'arabera',\n",
       " 'arabera',\n",
       " 'arabera',\n",
       " 'argi',\n",
       " 'arratsaldero',\n",
       " 'arte',\n",
       " 'artean',\n",
       " 'asko',\n",
       " 'aspaldiko',\n",
       " 'aurrera',\n",
       " 'aurrera',\n",
       " 'azkenez',\n",
       " 'azkenik',\n",
       " 'azkenik',\n",
       " 'ba',\n",
       " 'bada',\n",
       " 'bada ',\n",
       " 'bada ',\n",
       " 'bada ',\n",
       " 'badarik',\n",
       " 'badarik',\n",
       " 'badarik ',\n",
       " 'badere',\n",
       " 'bai',\n",
       " 'baina',\n",
       " 'baina',\n",
       " 'baina ',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baino',\n",
       " 'baita',\n",
       " 'baizik ',\n",
       " 'baldin',\n",
       " 'baldin',\n",
       " 'barren',\n",
       " 'bat',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batean',\n",
       " 'batek',\n",
       " 'baten',\n",
       " 'batera',\n",
       " 'batez',\n",
       " 'bati',\n",
       " 'batzuei',\n",
       " 'batzuek',\n",
       " 'batzuetan',\n",
       " 'batzuk',\n",
       " 'bazen',\n",
       " 'bederen',\n",
       " 'bederik',\n",
       " 'beharrez',\n",
       " 'behiala',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behin',\n",
       " 'behinik',\n",
       " 'behinola',\n",
       " 'behintzat',\n",
       " 'bera',\n",
       " 'beraiek',\n",
       " 'beranduago',\n",
       " 'berau',\n",
       " 'berauek',\n",
       " 'beraz',\n",
       " 'beraz ',\n",
       " 'bere',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union Words\n",
    "### Union words are the collections of all US Presidents' speeche's word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT', 'HARRY', 'S', '.', 'TRUMAN', \"'\", 'S', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.state_union.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_words = [word for word in nltk.corpus.state_union.words() if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assured',\n",
       " 'and',\n",
       " 'way',\n",
       " 'of',\n",
       " 'of',\n",
       " 'economic',\n",
       " 'the',\n",
       " 'on',\n",
       " 'an',\n",
       " 'recommended']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_words[10000:11000:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350715"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Many international media outlets in the past have mocked former US President Donald Trump for his views and opinions by making comics and cartoon characters on him. However, this time around, the former President joined their league not to poke fun but to launch his digital trading card business. \n",
    "Mr Trump's \"major announcement\" was teased by a superhero-themed video on his social media platform- Truth Social and it sparked a swirl of speculation on Wednesday. It was later revealed by the President himself that he is launching an online store to sell $99 digital trading cards of himself in various avatars- a superhero, an astronaut, an Old West sheriff and a series of other figures. \n",
    "\n",
    "According to a report in the New York Post, citing his announcement from Truth Social (available to US users only)  Mr Trump will be seen with a chiselled chest wearing a cape, triumphantly riding an elephant, and wearing a dapper James Bond-style tuxedo. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many international media outlets in the past have mocked former US President Donald Trump for his views and opinions by making comics and cartoon characters on him. However, this time around, the former President joined their league not to poke fun but to launch his digital trading card business. \n",
      "Mr Trump's \"major announcement\" was teased by a superhero-themed video on his social media platform- Truth Social and it sparked a swirl of speculation on Wednesday. It was later revealed by the President himself that he is launching an online store to sell $99 digital trading cards of himself in various avatars- a superhero, an astronaut, an Old West sheriff and a series of other figures. \n",
      "\n",
      "According to a report in the New York Post, citing his announcement from Truth Social (available to US users only)  Mr Trump will be seen with a chiselled chest wearing a cape, triumphantly riding an elephant, and wearing a dapper James Bond-style tuxedo. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Many international media outlets in the past have mocked former US President Donald Trump for his views and opinions by making comics and cartoon characters on him. However, this time around, the former President joined their league not to poke fun but to launch his digital trading card business. \\nMr Trump\\'s \"major announcement\" was teased by a superhero-themed video on his social media platform- Truth Social and it sparked a swirl of speculation on Wednesday. It was later revealed by the President himself that he is launching an online store to sell $99 digital trading cards of himself in various avatars- a superhero, an astronaut, an Old West sheriff and a series of other figures. \\n\\nAccording to a report in the New York Post, citing his announcement from Truth Social (available to US users only)  Mr Trump will be seen with a chiselled chest wearing a cape, triumphantly riding an elephant, and wearing a dapper James Bond-style tuxedo. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KALYANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'international', 'media', 'outlets', 'in', 'the', 'past', 'have', 'mocked', 'former', 'US', 'President', 'Donald', 'Trump', 'for', 'his', 'views', 'and', 'opinions', 'by', 'making', 'comics', 'and', 'cartoon', 'characters', 'on', 'him', '.', 'However', ',', 'this', 'time', 'around', ',', 'the', 'former', 'President', 'joined', 'their', 'league', 'not', 'to', 'poke', 'fun', 'but', 'to', 'launch', 'his', 'digital', 'trading', 'card', 'business', '.', 'Mr', 'Trump', \"'s\", '``', 'major', 'announcement', \"''\", 'was', 'teased', 'by', 'a', 'superhero-themed', 'video', 'on', 'his', 'social', 'media', 'platform-', 'Truth', 'Social', 'and', 'it', 'sparked', 'a', 'swirl', 'of', 'speculation', 'on', 'Wednesday', '.', 'It', 'was', 'later', 'revealed', 'by', 'the', 'President', 'himself', 'that', 'he', 'is', 'launching', 'an', 'online', 'store', 'to', 'sell', '$', '99', 'digital', 'trading', 'cards', 'of', 'himself', 'in', 'various', 'avatars-', 'a', 'superhero', ',', 'an', 'astronaut', ',', 'an', 'Old', 'West', 'sheriff', 'and', 'a', 'series', 'of', 'other', 'figures', '.', 'According', 'to', 'a', 'report', 'in', 'the', 'New', 'York', 'Post', ',', 'citing', 'his', 'announcement', 'from', 'Truth', 'Social', '(', 'available', 'to', 'US', 'users', 'only', ')', 'Mr', 'Trump', 'will', 'be', 'seen', 'with', 'a', 'chiselled', 'chest', 'wearing', 'a', 'cape', ',', 'triumphantly', 'riding', 'an', 'elephant', ',', 'and', 'wearing', 'a', 'dapper', 'James', 'Bond-style', 'tuxedo', '.']\n"
     ]
    }
   ],
   "source": [
    "stopword_text = nltk.word_tokenize(text)\n",
    "print(stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(stopword_text)\n",
    "size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 19191, 'of': 12854, 'to': 11868, 'and': 11748, 'in': 6936, 'a': 5837, 'our': 5141, 'we': 4338, 'that': 4309, 'for': 4070, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_u = nltk.FreqDist(union_words)\n",
    "fd_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 8, ',': 7, 'and': 5, '.': 5, 'to': 5, 'the': 4, 'his': 4, 'an': 4, 'in': 3, 'President': 3, ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_text = nltk.FreqDist(stopword_text)\n",
    "fd_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Many',\n",
       " 'international',\n",
       " 'media',\n",
       " 'outlets',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'have',\n",
       " 'mocked',\n",
       " 'former',\n",
       " 'US',\n",
       " 'President',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'for',\n",
       " 'his',\n",
       " 'views',\n",
       " 'and',\n",
       " 'opinions',\n",
       " 'by',\n",
       " 'making',\n",
       " 'comics',\n",
       " 'and',\n",
       " 'cartoon',\n",
       " 'characters',\n",
       " 'on',\n",
       " 'him',\n",
       " 'However',\n",
       " 'this',\n",
       " 'time',\n",
       " 'around',\n",
       " 'the',\n",
       " 'former',\n",
       " 'President',\n",
       " 'joined',\n",
       " 'their',\n",
       " 'league',\n",
       " 'not',\n",
       " 'to',\n",
       " 'poke',\n",
       " 'fun',\n",
       " 'but',\n",
       " 'to',\n",
       " 'launch',\n",
       " 'his',\n",
       " 'digital',\n",
       " 'trading',\n",
       " 'card',\n",
       " 'business',\n",
       " 'Mr',\n",
       " 'Trump',\n",
       " 'major',\n",
       " 'announcement',\n",
       " 'was',\n",
       " 'teased',\n",
       " 'by',\n",
       " 'a',\n",
       " 'video',\n",
       " 'on',\n",
       " 'his',\n",
       " 'social',\n",
       " 'media',\n",
       " 'Truth',\n",
       " 'Social',\n",
       " 'and',\n",
       " 'it',\n",
       " 'sparked',\n",
       " 'a',\n",
       " 'swirl',\n",
       " 'of',\n",
       " 'speculation',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " 'It',\n",
       " 'was',\n",
       " 'later',\n",
       " 'revealed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'President',\n",
       " 'himself',\n",
       " 'that',\n",
       " 'he',\n",
       " 'is',\n",
       " 'launching',\n",
       " 'an',\n",
       " 'online',\n",
       " 'store',\n",
       " 'to',\n",
       " 'sell',\n",
       " 'digital',\n",
       " 'trading',\n",
       " 'cards',\n",
       " 'of',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'various',\n",
       " 'a',\n",
       " 'superhero',\n",
       " 'an',\n",
       " 'astronaut',\n",
       " 'an',\n",
       " 'Old',\n",
       " 'West',\n",
       " 'sheriff',\n",
       " 'and',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'other',\n",
       " 'figures',\n",
       " 'According',\n",
       " 'to',\n",
       " 'a',\n",
       " 'report',\n",
       " 'in',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Post',\n",
       " 'citing',\n",
       " 'his',\n",
       " 'announcement',\n",
       " 'from',\n",
       " 'Truth',\n",
       " 'Social',\n",
       " 'available',\n",
       " 'to',\n",
       " 'US',\n",
       " 'users',\n",
       " 'only',\n",
       " 'Mr',\n",
       " 'Trump',\n",
       " 'will',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'with',\n",
       " 'a',\n",
       " 'chiselled',\n",
       " 'chest',\n",
       " 'wearing',\n",
       " 'a',\n",
       " 'cape',\n",
       " 'triumphantly',\n",
       " 'riding',\n",
       " 'an',\n",
       " 'elephant',\n",
       " 'and',\n",
       " 'wearing',\n",
       " 'a',\n",
       " 'dapper',\n",
       " 'James',\n",
       " 'tuxedo']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_txt_sw = [word for word in stopword_text if word.isalpha()]\n",
    "fd_txt_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 8, ',': 7, 'and': 5, '.': 5, 'to': 5, 'the': 4, 'his': 4, 'an': 4, 'in': 3, 'President': 3, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_corpus = nltk.word_tokenize(text)\n",
    "fd_p = nltk.FreqDist(news_corpus)\n",
    "fd_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'most_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfd_txt_sw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_common\u001b[49m(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'most_common'"
     ]
    }
   ],
   "source": [
    "fd_txt_sw.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 19191), ('of', 12854), ('to', 11868), ('and', 11748), ('in', 6936)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_u.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a         ,       and         .        to       the       his        an        in President \n",
      "        8         7         5         5         5         4         4         4         3         3 \n"
     ]
    }
   ],
   "source": [
    "fd_p.tabulate(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"English\")\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expenditures',\n",
       " 'receipts',\n",
       " 'authorization',\n",
       " 'recommended',\n",
       " 'Budget',\n",
       " 'total',\n",
       " 'next',\n",
       " 'fiscal',\n",
       " 'year',\n",
       " 'year']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_union_words = [word for word in union_words if word.lower() not in stopwords]\n",
    "net_union_words[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_stopwords :\t ['in', 'the', 'have', 'for', 'his', 'and', 'by', 'and', 'on', 'him', 'this', 'the', 'their', 'not', 'to', 'but', 'to', 'his', 'was', 'by', 'a', 'on', 'his', 'and', 'it', 'a', 'of', 'on', 'It', 'was', 'by', 'the', 'himself', 'that', 'he', 'is', 'an', 'to', 'of', 'himself', 'in', 'a', 'an', 'an', 'and', 'a', 'of', 'other', 'to', 'a', 'in', 'the', 'his', 'from', 'to', 'only', 'will', 'be', 'with', 'a', 'a', 'an', 'and', 'a']\n",
      "\n",
      "news_corpus_net :\t ['Many', 'international', 'media', 'outlets', 'past', 'mocked', 'former', 'US', 'President', 'Donald', 'Trump', 'views', 'opinions', 'making', 'comics', 'cartoon', 'characters', '.', 'However', ',', 'time', 'around', ',', 'former', 'President', 'joined', 'league', 'poke', 'fun', 'launch', 'digital', 'trading', 'card', 'business', '.', 'Mr', 'Trump', \"'s\", '``', 'major', 'announcement', \"''\", 'teased', 'superhero-themed', 'video', 'social', 'media', 'platform-', 'Truth', 'Social', 'sparked', 'swirl', 'speculation', 'Wednesday', '.', 'later', 'revealed', 'President', 'launching', 'online', 'store', 'sell', '$', '99', 'digital', 'trading', 'cards', 'various', 'avatars-', 'superhero', ',', 'astronaut', ',', 'Old', 'West', 'sheriff', 'series', 'figures', '.', 'According', 'report', 'New', 'York', 'Post', ',', 'citing', 'announcement', 'Truth', 'Social', '(', 'available', 'US', 'users', ')', 'Mr', 'Trump', 'seen', 'chiselled', 'chest', 'wearing', 'cape', ',', 'triumphantly', 'riding', 'elephant', ',', 'wearing', 'dapper', 'James', 'Bond-style', 'tuxedo', '.']\n"
     ]
    }
   ],
   "source": [
    "news_stopwords = [w for w in news_corpus if w.lower() in stopwords]\n",
    "print(\"news_stopwords :\\t\",news_stopwords)\n",
    "print()\n",
    "news_corpus_net = [w for w in news_corpus if w.lower() not in stopwords]\n",
    "print(\"news_corpus_net :\\t\",news_corpus_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180589"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net_union_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordance and Collocation\n",
    "Collection of particular word location, along with their context. Can be used to find the\n",
    "1.  How many times the word will be appear?\n",
    "2.  Where each occurence appears?\n",
    "3.  What words was surround, each occurence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 432 matches:\n",
      " PRESIDENT HARRY S . TRUMAN ' S ADDRESS BEFOR\n",
      "pril 16 , 1945 Mr . Speaker , Mr . President , Members of the Congress : It is \n",
      " the mortal remains of our beloved President , Franklin Delano Roosevelt . At a\n",
      "fice - in the memory of our fallen President - we shall not fail ! It is not en\n",
      "servant of my Lord and my people . PRESIDENT HARRY S . TRUMAN ' S MESSAGE TO TH\n"
     ]
    }
   ],
   "source": [
    "union_corpus = nltk.Text(nltk.corpus.state_union.words())\n",
    "union_corpus.concordance(\"President\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong economy ; where `` Made in the USA '' is recognized around the world as \n",
      "bearing the proud stamp \" Made in the USA .\" Today , record high exports accoun\n",
      "tablish universal savings accounts -- USA accounts -- to give all Americans the\n",
      "a help for those least able to save . USA accounts will help all Americans to s\n",
      "Social Security , Medicare , creating USA accounts : This is the right way to u\n",
      "ngthening Medicare , establishing the USA accounts , supporting long - term car\n",
      "merica , I invite you to join the new USA Freedom Corps . The Freedom Corps wil\n",
      "ughout the world . One purpose of the USA Freedom Corps will be homeland securi\n",
      "lented teachers in troubled schools . USA Freedom Corps will expand and improve\n",
      " my fellow citizens to participate in USA Freedom Corps , which is enlisting te\n"
     ]
    }
   ],
   "source": [
    "union_corpus_cc_list = union_corpus.concordance_list(\"USA\", lines = 15)\n",
    "for entry in union_corpus_cc_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation\n",
    "Series of words that will be frequently appeared in the given document.\n",
    "It is made of two or more words.\n",
    "NLTK provides classes to handle the following type of collocation.:\n",
    "\n",
    "    1. Bi-Gram      :   Frequent 2-words combination\n",
    "\n",
    "    2. Tri-Gram     :       \"    3-words    \"\n",
    "    \n",
    "    3. Quad-Gram    :       \"    4-words    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 2599),\n",
       " (('in', 'the'), 1851),\n",
       " (('to', 'the'), 1143),\n",
       " (('of', 'our'), 1135),\n",
       " (('and', 'the'), 841),\n",
       " (('for', 'the'), 774),\n",
       " (('the', 'world'), 645),\n",
       " (('the', 'Congress'), 598),\n",
       " (('will', 'be'), 569),\n",
       " (('we', 'must'), 498)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_corpus = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "union_corpus_bigram_cl = nltk.collocations.BigramCollocationFinder.from_words(union_corpus)\n",
    "union_corpus_bigram_cl.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294),\n",
       " (('the', 'American', 'people'), 185),\n",
       " (('of', 'the', 'world'), 154),\n",
       " (('of', 'the', 'United'), 145),\n",
       " (('to', 'the', 'Congress'), 139),\n",
       " (('in', 'the', 'world'), 131),\n",
       " (('the', 'fiscal', 'year'), 109),\n",
       " (('of', 'the', 'Congress'), 102),\n",
       " (('of', 'the', 'Union'), 102),\n",
       " (('the', 'Federal', 'Government'), 102)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_corpus = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "union_corpus_trigram_cl = nltk.collocations.TrigramCollocationFinder.from_words(union_corpus)\n",
    "union_corpus_trigram_cl.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the', 'United', 'States'), 110),\n",
       " (('I', 'ask', 'you', 'to'), 69),\n",
       " (('State', 'of', 'the', 'Union'), 58),\n",
       " (('STATE', 'OF', 'THE', 'UNION'), 52),\n",
       " (('ON', 'THE', 'STATE', 'OF'), 50),\n",
       " (('THE', 'STATE', 'OF', 'THE'), 50),\n",
       " (('in', 'the', 'fiscal', 'year'), 47),\n",
       " (('CONGRESS', 'ON', 'THE', 'STATE'), 46),\n",
       " (('the', 'state', 'of', 'the'), 45),\n",
       " (('of', 'the', 'American', 'people'), 42)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_corpus = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "union_corpus_quadgram_cl = nltk.collocations.QuadgramCollocationFinder.from_words(union_corpus)\n",
    "union_corpus_quadgram_cl.ngram_fd.most_common(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39e96fb8295ea3e25cddb506332d132b1309cf2f488544f7f2cf02a54f7887e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
